{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalization\n",
    "- Pre-tokenization\n",
    "- Build models\n",
    "- Training the tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators3 = {'<<=', '>>='}\n",
    "operators2 = {\n",
    "    '->', '++', '--',\n",
    "    '!~', '<<', '>>', '<=', '>=',\n",
    "    '==', '!=', '&&', '||', '+=',\n",
    "    '-=', '*=', '/=', '%=', '&=', '^=', '|='\n",
    "}\n",
    "operators1 = {\n",
    "    '(', ')', '[', ']', '.',\n",
    "    '+', '-', '*', '&', '/',\n",
    "    '%', '<', '>', '^', '|',\n",
    "    '=', ',', '?', ':', ';',\n",
    "    '{', '}'\n",
    "}\n",
    "def tokenize(line):\n",
    "        line = line.replace(\"\\n\",\" \").replace(\"\\r\\n\",\" \").replace(\"\\r\",\" \")\n",
    "        tmp, w = [], []\n",
    "        i = 0\n",
    "        while i < len(line):\n",
    "            # Ignore spaces and combine previously collected chars to form words\n",
    "            if line[i] == ' ':\n",
    "                tmp.append(''.join(w))\n",
    "                tmp.append(line[i])\n",
    "                w = []\n",
    "                i += 1\n",
    "            # Check operators and append to final list\n",
    "            elif line[i:i + 3] in operators3:\n",
    "                tmp.append(''.join(w))\n",
    "                tmp.append(line[i:i + 3])\n",
    "                w = []\n",
    "                i += 3\n",
    "            elif line[i:i + 2] in operators2:\n",
    "                tmp.append(''.join(w))\n",
    "                tmp.append(line[i:i + 2])\n",
    "                w = []\n",
    "                i += 2\n",
    "            elif line[i] in operators1:\n",
    "                tmp.append(''.join(w))\n",
    "                tmp.append(line[i])\n",
    "                w = []\n",
    "                i += 1\n",
    "            # Character appended to word list\n",
    "            else:\n",
    "                w.append(line[i])\n",
    "                i += 1\n",
    "        # Filter out irrelevant strings\n",
    "        res = list(filter(lambda c: c != '', tmp))\n",
    "        return ' '.join(list(filter(lambda c: c != ' ', res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(string):\n",
    "    pattern = r\"(\\\".*?\\\"|\\'.*?\\')|(/\\*.*?\\*/|//[^\\r\\n]*$)\"\n",
    "    # first group captures quoted strings (double or single)\n",
    "    # second group captures comments (//single-line or /* multi-line */)\n",
    "    regex = re.compile(pattern, re.MULTILINE|re.DOTALL)\n",
    "    def _replacer(match):\n",
    "        # if the 2nd group is not None, then we have captured a real comment string.\n",
    "        if match.group(2) is not None:\n",
    "            return \"\" \n",
    "        else: # otherwise, we will return the 1st group\n",
    "            return match.group(1) \n",
    "    return regex.sub(_replacer, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators  = ['++', '--', '-', '!', '~', '**', '*', '/', '%', '+','<<', '>>', '&', '^', '|','<', '>', '<=', '>=', '==', '!=' , '&&', '||', '=', '|=', '^=', '&=', '<<=', '>>=', '+=', '-=', '*=', '/=', '%=', ',', ':'  ]\n",
    "global_variable = ['abi.decode', 'abi.encode', 'abi.encodePacked', 'abi.encodeWithSelector', 'abi.encodeCall', 'abi.encodeWithSignature','bytes.concat','string.concat', 'block.basefee', 'block.chainid',  'block.coinbase', 'block.difficulty', 'block.gaslimit', 'block.number', 'block.prevrandao',  'block.timestamp', 'gasleft', 'msg.data','msg.sender','msg.sig','msg.value', 'tx.gasprice', 'tx.origin' , 'assert', 'require' , 'revert', 'blockhash' , 'keccak256', 'sha256' , 'ripemd160', 'ecrecover', 'addmod', 'mulmod', 'selfdestruct' ]\n",
    "Other_keyword = ['bytes1','bytes2','bytes3','bytes4','bytes5','bytes6','bytes7','bytes8','bytes9','bytes10','bytes11','bytes12','bytes13','bytes14','bytes15','bytes16','bytes17','bytes18','bytes19','bytes20','bytes21','bytes22','bytes23','bytes24','bytes25','bytes26','bytes27','bytes28','bytes29','bytes30','bytes31','bytes32']\n",
    "number = ['wei','gwei','ether','seconds','minutes','hours','days','weeks','years' ]\n",
    "evm_built = ['stop','add','sub','mul','div','sdiv','mod','smod','exp','not','lt','gt','slt','sgt','eq','iszero','and','or','xor','byte','shl','shr','sar','addmod','mulmod','signextend','keccak256','pop','mload','mstore','mstore8','sload','sstore','msize','gas','address','balance','selfbalance','caller','callvalue','calldataload','calldatasize','calldatacopy','extcodesize','extcodecopy','returndatasize','returndatacopy','extcodehash','create','create2','call','callcode','delegatecall','staticcall','return','revert','selfdestruct','invalid','log0','log1','log2','log3','log4','chainid','origin','gasprice','blockhash','coinbase','timestamp','number','difficulty','prevrandao','gaslimit','basefee']\n",
    "uint = ['uint','uint8','uint16','uint24','uint32','uint40','uint48','uint56','uint64','uint72','uint80','uint88','uint96','uint104','uint112','uint120','uint128','uint136','uint144','uint152','uint160','uint168','uint176','uint184','uint192','uint200','uint208','uint216','uint224','uint232','uint240','uint248','uint256']\n",
    "int_ =['int','int8','int16','int24','int32','int40','int48','int56','int64','int72','int80','int88','int96','int104','int112','int120','int128','int136','int144','int152','int160','int168','int176','int184','int192','int200','int208','int216','int224','int232','int240','int248','int256']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"/home/bombbom/Documents/NLP_in_Detection_System/dataset_example/labeled_SBW_datasets.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>source_code</th>\n",
       "      <th>categories</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x21e13cb3f3f26f92a62ac7adab4093e8997d1fb1</td>\n",
       "      <td>pragma solidity ^0.4.18;\\n\\n// ---------------...</td>\n",
       "      <td>['Other', 'arithmetic', 'arithmetic']</td>\n",
       "      <td>[154, 141, 103]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x344005c29af957567f0b40950b425ed018b92170</td>\n",
       "      <td>pragma solidity  ^0.4.21;\\n\\n\\ncontract DSMath...</td>\n",
       "      <td>['arithmetic', 'reentrancy', 'arithmetic', 'ar...</td>\n",
       "      <td>[201, 16, 209, 176, 146, 154, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x44e320110176c11c93e116f6770f13d96deded43</td>\n",
       "      <td>pragma solidity ^0.4.20;\\n\\n\\ncontract Ownable...</td>\n",
       "      <td>['arithmetic']</td>\n",
       "      <td>[82, 46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x5ecd84482176db90bb741ddc8c2f9ccc290e29ce</td>\n",
       "      <td>pragma solidity ^0.4.8;\\ncontract Token{\\n    ...</td>\n",
       "      <td>['arithmetic', 'unchecked_low_calls', 'arithme...</td>\n",
       "      <td>[99, 38, 78, 48, 49, 60, 93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xcaf187eb618d2335b4130d784a697be96f4b07b9</td>\n",
       "      <td>pragma solidity 0.4.15;\\n\\ncontract RegistryIC...</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>[80, 28, 63]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47326</th>\n",
       "      <td>0x7f650f3b231d3a32c2b0e2940e870acdd4aa9961</td>\n",
       "      <td>pragma solidity ^0.4.24;\\n\\n\\n\\n\\n/**\\n * @tit...</td>\n",
       "      <td>['reentrancy', 'arithmetic', 'time_manipulatio...</td>\n",
       "      <td>[258, 264, 245, 253, 287]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47327</th>\n",
       "      <td>0xc73f2474001ad1d6aed615af53631148cf98de6b</td>\n",
       "      <td>pragma solidity ^0.4.18;\\n\\n// ---------------...</td>\n",
       "      <td>['Other', 'arithmetic', 'arithmetic']</td>\n",
       "      <td>[200, 218, 128, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47328</th>\n",
       "      <td>0xb2105f178abe620ddbb86a70afa94bfa9daa4d01</td>\n",
       "      <td>pragma solidity ^0.4.23;\\n\\nlibrary SafeMath {...</td>\n",
       "      <td>['arithmetic', 'arithmetic', 'front_running']</td>\n",
       "      <td>[124, 20, 205]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47329</th>\n",
       "      <td>0xe2d4b960d0c639633582cddef57528461e62083d</td>\n",
       "      <td>pragma solidity ^0.4.23;\\n\\n\\n/// @title Multi...</td>\n",
       "      <td>['arithmetic', 'Other', 'unchecked_low_calls',...</td>\n",
       "      <td>[140, 142, 23, 282, 410, 157, 287, 296, 302, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47330</th>\n",
       "      <td>0xb44a2acd38f7ee6ae965aa8d77f4f14849770203</td>\n",
       "      <td>pragma solidity ^0.4.2;  \\n\\ncontract Maurel {...</td>\n",
       "      <td>['arithmetic']</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47331 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          address  \\\n",
       "0      0x21e13cb3f3f26f92a62ac7adab4093e8997d1fb1   \n",
       "1      0x344005c29af957567f0b40950b425ed018b92170   \n",
       "2      0x44e320110176c11c93e116f6770f13d96deded43   \n",
       "3      0x5ecd84482176db90bb741ddc8c2f9ccc290e29ce   \n",
       "4      0xcaf187eb618d2335b4130d784a697be96f4b07b9   \n",
       "...                                           ...   \n",
       "47326  0x7f650f3b231d3a32c2b0e2940e870acdd4aa9961   \n",
       "47327  0xc73f2474001ad1d6aed615af53631148cf98de6b   \n",
       "47328  0xb2105f178abe620ddbb86a70afa94bfa9daa4d01   \n",
       "47329  0xe2d4b960d0c639633582cddef57528461e62083d   \n",
       "47330  0xb44a2acd38f7ee6ae965aa8d77f4f14849770203   \n",
       "\n",
       "                                             source_code  \\\n",
       "0      pragma solidity ^0.4.18;\\n\\n// ---------------...   \n",
       "1      pragma solidity  ^0.4.21;\\n\\n\\ncontract DSMath...   \n",
       "2      pragma solidity ^0.4.20;\\n\\n\\ncontract Ownable...   \n",
       "3      pragma solidity ^0.4.8;\\ncontract Token{\\n    ...   \n",
       "4      pragma solidity 0.4.15;\\n\\ncontract RegistryIC...   \n",
       "...                                                  ...   \n",
       "47326  pragma solidity ^0.4.24;\\n\\n\\n\\n\\n/**\\n * @tit...   \n",
       "47327  pragma solidity ^0.4.18;\\n\\n// ---------------...   \n",
       "47328  pragma solidity ^0.4.23;\\n\\nlibrary SafeMath {...   \n",
       "47329  pragma solidity ^0.4.23;\\n\\n\\n/// @title Multi...   \n",
       "47330  pragma solidity ^0.4.2;  \\n\\ncontract Maurel {...   \n",
       "\n",
       "                                              categories  \\\n",
       "0                  ['Other', 'arithmetic', 'arithmetic']   \n",
       "1      ['arithmetic', 'reentrancy', 'arithmetic', 'ar...   \n",
       "2                                         ['arithmetic']   \n",
       "3      ['arithmetic', 'unchecked_low_calls', 'arithme...   \n",
       "4                                              ['Other']   \n",
       "...                                                  ...   \n",
       "47326  ['reentrancy', 'arithmetic', 'time_manipulatio...   \n",
       "47327              ['Other', 'arithmetic', 'arithmetic']   \n",
       "47328      ['arithmetic', 'arithmetic', 'front_running']   \n",
       "47329  ['arithmetic', 'Other', 'unchecked_low_calls',...   \n",
       "47330                                     ['arithmetic']   \n",
       "\n",
       "                                                   lines  \n",
       "0                                        [154, 141, 103]  \n",
       "1                      [201, 16, 209, 176, 146, 154, 29]  \n",
       "2                                               [82, 46]  \n",
       "3                           [99, 38, 78, 48, 49, 60, 93]  \n",
       "4                                           [80, 28, 63]  \n",
       "...                                                  ...  \n",
       "47326                          [258, 264, 245, 253, 287]  \n",
       "47327                               [200, 218, 128, 102]  \n",
       "47328                                     [124, 20, 205]  \n",
       "47329  [140, 142, 23, 282, 410, 157, 287, 296, 302, 3...  \n",
       "47330                                                [7]  \n",
       "\n",
       "[47331 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['source_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4931/3853744767.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.source_code = data.source_code.apply(remove_comments)\n"
     ]
    }
   ],
   "source": [
    "data.source_code = data.source_code.apply(remove_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4931/1830387800.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.source_code = data.source_code.apply(tokenize)\n"
     ]
    }
   ],
   "source": [
    "data.source_code = data.source_code.apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source_code'],\n",
       "    num_rows: 47331\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a Python generator, we can avoid Python loading anything into memory until it’s actually necessary. To create such a generator, you just to need to replace the brackets with parentheses:\n",
    "# training_corpus = (\n",
    "#     data[i : i + 1000][\"source_code\"]\n",
    "#     for i in range(0, len(data), 1000)\n",
    "# )\n",
    "# This line of code doesn’t fetch any elements of the dataset; it just creates an object you can use in a Python for loop. The texts will only be loaded when you need them (that is, when you’re at the step of the for loop that requires them), and only 1,000 texts at a time will be loaded. This way you won’t exhaust all your memory even if you are processing a huge dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    return (\n",
    "        data[i : i + 1000][\"source_code\"]\n",
    "        for i in range(0, len(data), 1000)\n",
    "    )\n",
    "\n",
    "\n",
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_training_corpus.<locals>.<genexpr> at 0x7f2e7e460040>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pr',\n",
       " '##ag',\n",
       " '##ma',\n",
       " 'solid',\n",
       " '##ity',\n",
       " '^',\n",
       " '0',\n",
       " '.',\n",
       " '8',\n",
       " '.',\n",
       " '17',\n",
       " ';',\n",
       " 'contract',\n",
       " 'hello',\n",
       " '##world',\n",
       " '{',\n",
       " 'string',\n",
       " 'public',\n",
       " 'greet',\n",
       " '=',\n",
       " '\"',\n",
       " 'hello',\n",
       " 'world',\n",
       " '!',\n",
       " '\"',\n",
       " ';',\n",
       " '}']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = '''pragma solidity ^0.8.17;\n",
    "\n",
    "contract HelloWorld {\n",
    "    string public greet = \"Hello World!\";\n",
    "}'''\n",
    "\n",
    "tokens = old_tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer.add_tokens(list(operators))\n",
    "old_tokenizer.add_tokens(list(global_variable))\n",
    "old_tokenizer.add_tokens(list(Other_keyword))\n",
    "old_tokenizer.add_tokens(list(number))\n",
    "old_tokenizer.add_tokens(list(evm_built))\n",
    "old_tokenizer.add_tokens(list(uint))\n",
    "old_tokenizer.add_tokens(list(int_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'pr',\n",
       " '##ag',\n",
       " '##ma',\n",
       " 'solid',\n",
       " '##ity',\n",
       " '^',\n",
       " '0',\n",
       " '.',\n",
       " '8',\n",
       " '.',\n",
       " '17',\n",
       " ';',\n",
       " 'contract',\n",
       " 'hello',\n",
       " '##world',\n",
       " '{',\n",
       " 'string',\n",
       " 'public',\n",
       " 'greet',\n",
       " '=',\n",
       " '\"',\n",
       " 'hello',\n",
       " 'world',\n",
       " '!',\n",
       " '\"',\n",
       " ';',\n",
       " '}',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer(example).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 10975, 8490, 2863, 5024, 3012, 1034, 1014, 1012, 1022, 1012, 2459, 1025, 3206, 7592, 11108, 1063, 5164, 2270, 17021, 1027, 1000, 7592, 2088, 999, 1000, 1025, 1065, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pr'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer.decode(10975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pragma',\n",
       " 'solidity',\n",
       " '^',\n",
       " '0',\n",
       " '.',\n",
       " '8',\n",
       " '.',\n",
       " '17',\n",
       " ';',\n",
       " 'contract',\n",
       " 'hello',\n",
       " '##world',\n",
       " '{',\n",
       " 'string',\n",
       " 'public',\n",
       " 'gre',\n",
       " '##et',\n",
       " '=',\n",
       " '\"',\n",
       " 'hello',\n",
       " 'world',\n",
       " '!',\n",
       " '\"',\n",
       " ';',\n",
       " '}']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/bombbom/Documents/NLP_in_Detection_System/save_model/tokenizer/tokenizer_config.json',\n",
       " '/home/bombbom/Documents/NLP_in_Detection_System/save_model/tokenizer/special_tokens_map.json',\n",
       " '/home/bombbom/Documents/NLP_in_Detection_System/save_model/tokenizer/vocab.txt',\n",
       " '/home/bombbom/Documents/NLP_in_Detection_System/save_model/tokenizer/added_tokens.json',\n",
       " '/home/bombbom/Documents/NLP_in_Detection_System/save_model/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"/home/bombbom/Documents/NLP_in_Detection_System/save_model/tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"huggingface-course\" below with your actual namespace to use your own tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/bombbom/Documents/NLP_in_Detection_System/save_model/tokenizer/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
